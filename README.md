# ðŸ§ª CleanCity â€” QA Case Study (Web Platform)

**Role:** QA Engineer (Manual + Automation)
**Scope:** Web-based application
**Focus:** Functional testing â€¢ Regression â€¢ Bug reporting â€¢ Test automation

## Overview

This repository contains a QA case study for CleanCity, a web-based application used as a test subject to demonstrate professional QA execution.

The purpose of this project is to showcase:

- Manual testing approach
- Test planning and execution
- Clear defect reporting
- Risk-based automation decisions
> This is a QA artefact, not an application development project.

## Testing Scope

### In Scope

* Functional testing
* Regression testing
* Exploratory testing
* Cross-browser testing (Chrome, Firefox, Edge)
* UI-level automation (critical paths)

### Out of Scope

* Backend testing
* Performance testing
* Security testing
* CI/CD integration
* Mobile testing

## QA Approach

Testing was conducted using a risk-based strategy, focusing on:

- Core user flows
- Data validation
- State changes
- Error handling
- Usability risks

Manual testing was executed first to establish system understanding and defect baselines.
Automation was introduced selectively for stable, high-value user journeys.

## Repository Structure
```
cleancity-qa-case-study/
â”œâ”€â”€ app/                     # Original application (unmodified)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ manual/
â”‚   â”‚   â”œâ”€â”€ test-plan.md
â”‚   â”‚   â”œâ”€â”€ test-cases.md
â”‚   â”‚   â”œâ”€â”€ exploratory-notes.md
â”‚   â”‚   â””â”€â”€ defect-report.md
â”‚   â””â”€â”€ automation/
â”‚       â”œâ”€â”€ cypress/
â”‚       â”œâ”€â”€ jest/
â”‚       â””â”€â”€ automation-scope.md
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ test-execution-report.md
â”‚   â”œâ”€â”€ defect-summary.md
â”‚   â””â”€â”€ qa-summary.md
â””â”€â”€ README.md
```

## Manual Testing

Manual testing focused on:

- User input validation
- Data persistence
- Filtering and state updates
- Error messaging and edge cases
- Basic accessibility and usability signals

Test cases were designed to be:

- Clear
- Reproducible
- Traceable to observed behavior

## Defect Reporting

Defects were logged with:

- Clear reproduction steps
- Expected vs actual behavior
- Severity and impact assessment

The goal was clarity and actionability, not volume.

## Test Automation

Automation was implemented to validate:

- Critical user flows
- Regression-prone functionality

### Tooling

- **Cypress** â€” End-to-end testing
- **Jest** â€” Component-level validation

Automation intentionally avoids full coverage in favor of:

- Stability
- Maintenance cost awareness
- Execution value

See `automation-scope.md` for rationale.

## Reporting & Outcomes

Testing concluded with:

- Test execution report
- Defect summary
- QA sign-off summary highlighting risks and recommendations

These artefacts reflect how QA results are communicated to **stakeholders and product teams**.

## Notes

- This project represents **QA execution only**
- The application under test was not authored by the QA engineer
- All findings are based on observed system behavior

## Author

**Mpumelelo Theophilas Nxazonke**
<br/>QA Engineer â€¢ SDET
<br/>South Africa

## License

MIT License
Educational and portfolio use only
